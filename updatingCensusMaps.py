# -*- coding: utf-8 -*-
"""updating_censusMaps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YJYppLjoIskJ-FM_h_pq16IXcYwSVlkm

# This script calls and processes Census ACS5 Summary table S1701 to visualize GMA cities, county & district/region value for:
- % children in poverty (field: 'S1701_C03_002E')
- % Individuals in poverty (all ages) (field: 'S1701_C03_001E')
- % Seniors in Poverty (>65 yrs) (field: 'S1701_C03_003E')

While cities & counties have direct percentages, GMA districts need to be separately aggregated. This is done by calling the county_view item from arcgis which labels each county with its respective region number. The counties are then grouped by the region number; the sum of the region's population in poverty divided by the sum the total population for each category gives the %.

THIS SCRIPT HAS TO BE RUN FROM ARCGIS PRO's PYTHON COMMAND PROMPT
"""

! pip install us
! pip install census
! pip install requests
! pip install python-dotenv

from census import Census
import us

import pandas as pd
import os
from dotenv import load_dotenv
load_dotenv()

census_api=os.getenv('CENSUS_API')
gac_username=os.getenv('GAC_USERNAME')
gac_password=os.getenv('GAC_PASSWORD')

c = Census(census_api)

# import requests as r
# import json
# import ast
# x=r.get("https://api.census.gov/data/2021/acs/acs5/subject?get=NAME,S1701_C03_001E&for=county:*&in=state:13")
# data_str=x.content
# data_str = data_str.decode("utf-8").replace("\n", "")
# #data_str
# data_list = ast.literal_eval(data_str)
# columns = data_list[0]
# data = data_list[1:]
# df = pd.DataFrame(data, columns=columns)
# df = df.rename(columns={"NAME": "county_name","S1701_C03_001E":"county_perc_indiv_pov",})

#COUNTY DF
ldict=c.acs5st.state_county(('NAME','S1701_C03_001E', 'S1701_C03_002E','S1701_C03_010E'), '13', Census.ALL)
df=pd.DataFrame(ldict)
df = df.rename(columns={"NAME": "county_name","S1701_C03_001E":"county_perc_indiv_pov","S1701_C03_002E":"county_perc_child_pov",
                        "S1701_C03_010E":"county_perc_senior_pov","county":"county_GEOID"})
df=df.drop(columns='state')
df['county_name'] = df['county_name'].str[:-9]
df["county_GEOID"]='13'+df["county_GEOID"]
df

#CITY DF
ldictcity=c.acs5st.state_place(('NAME','S1701_C03_001E',"S1701_C03_002E","S1701_C03_010E"), '13', Census.ALL)
dfcity=pd.DataFrame(ldictcity)
dfcity = dfcity.rename(columns={"NAME": "city_name","S1701_C03_001E":"city_perc_indiv_pov","S1701_C03_002E":"city_perc_child_pov",
                        "S1701_C03_010E":"city_perc_senior_pov","place":"city_geoid"})
dfcity=dfcity.drop(columns='state')
dfcity = dfcity[~dfcity['city_name'].str.contains('CDP')]
dfcity['city_name'] = dfcity['city_name'].str[:-9]
dfcity["city_geoid"]='13'+dfcity["city_geoid"].str.zfill(5)
dfcity

"""### Region Calculation"""

#calling data from census
ldictcr=c.acs5st.state_county(('NAME','S1701_C02_001E','S1701_C01_001E','S1701_C02_002E','S1701_C01_002E','S1701_C02_010E','S1701_C01_010E'), '13', Census.ALL)
dfcr=pd.DataFrame(ldictcr)
dfcr = dfcr.rename(columns={"NAME": "county_name","S1701_C02_001E":"county_tot_indiv_pov","S1701_C01_001E":"county_TOT_indiv",
                            "S1701_C02_002E":"county_tot_child_pov","S1701_C01_002E":"county_TOT_child",
                            "S1701_C02_010E":"county_tot_senior_pov","S1701_C01_010E":"county_TOT_senior",
                            "county":"county_GEOID"})
dfcr["county_GEOID"]='13'+dfcr["county_GEOID"]
dfcr

#arcgis connection
from arcgis.gis import GIS
from arcgis import features
gis = GIS("https://gacities.maps.arcgis.com/", gac_username, gac_password)
print(f"Connected to {gis.properties.portalHostname}")

# preparing county_view layer from arcgis
search_item = gis.content.search(query="title:county_view", item_type= "Feature Layer Collection")
counties_item=gis.content.get(search_item[0].id)
counties_flayer = counties_item.layers[0]
counties_fset = counties_flayer.query()
csdf= counties_fset.sdf
csdf=csdf[['county_GEOID','Region_Number']]
csdf

#joins
dfr=pd.merge(csdf, dfcr, on='county_GEOID', how='inner')
dfr=dfr.drop(columns=['state','county_GEOID','county_name'])
dfr = dfr.groupby('Region_Number')[['county_tot_indiv_pov', 'county_TOT_indiv',
                                   'county_tot_child_pov', 'county_TOT_child',
                                   'county_tot_senior_pov', 'county_TOT_senior']].sum().reset_index()
dfr['reg_perc_indiv_pov']=dfr['county_tot_indiv_pov']*100/ dfr['county_TOT_indiv']
dfr['reg_perc_child_pov']=dfr["county_tot_child_pov"]*100/ dfr['county_TOT_child']
dfr['reg_perc_senior_pov']=dfr['county_tot_senior_pov']*100/ dfr['county_TOT_senior']
dfr=round(dfr.drop(columns=['county_tot_indiv_pov', 'county_TOT_indiv',
                            'county_tot_child_pov', 'county_TOT_child',
                           'county_tot_senior_pov', 'county_TOT_senior']),1)
dfr['reg_no']=dfr['Region_Number'].astype(int)
dfr

# ##deleting file from arcgis if filename already exists
# def delete_existing_items(item_types, name_list):
#     for current_item_type in item_types:
#         for file_name in name_list:
#             search_result = gis.content.search(query=file_name, item_type=current_item_type)
#             if len(search_result) > 0:
#                 for item in search_result:
#                     print(item)
# #                     item.delete()
# #                     print("Deleted existing " + current_item_type + ": ", item)

"""### Creating CSVs for the 3 data frames to be saved in the current working directory"""


cwd= os.path.abspath(os.getcwd())

#CREATING CSVS for the city, county, & region

dfdict={'pov_region':dfr,'pov_county':df,'pov_city':dfcity}
for key,value in dfdict.items():
    my_csv=value.to_csv(cwd+'\\'+key+".csv", index=False, encoding='utf-8')
    path_csv= cwd+'\\'+ key+".csv"
    print(path_csv)
#     item_prop = {'title':key}
#     item_types = ["CSV"]
#     name_list = [key]
#     delete_existing_items(item_types, name_list)
#     csv_item = gis.content.add(item_properties=item_prop, data=path_csv)
#     csv_item.move("pov_fromScript")
#     print("updated csv")

"""# This script calls the GA & US values for the % categories mentioned
The result is stored in the 'pov_ga_us table' in arcgis
"""

# DF for GA & US
ga_values=c.acs5st.state(('NAME','S1701_C03_001E',"S1701_C03_002E","S1701_C03_010E"), '13')
us_values=c.acs5st.us(('NAME','S1701_C03_001E',"S1701_C03_002E","S1701_C03_010E"))
dfga=pd.DataFrame(ga_values)
dfus=pd.DataFrame(us_values)
dfga=dfga.drop(columns=['state'])
dfus=dfus.drop(columns=['us'])
dfga_us=pd.concat([dfga, dfus], ignore_index=True)

dfga_us = dfga_us.rename(columns={"S1701_C03_001E":"perc_indiv_pov","S1701_C03_002E":"perc_child_pov",
                        "S1701_C03_010E":"perc_senior_pov"})
pov_ga_us_csv=dfga_us.to_csv(cwd+'\\'+"pov_ga_us.csv")
print(cwd+'\\'+"pov_ga_us.csv")

# #inital publishing start
# item_prop = {'title':"pov_us_ga",'type':'CSV'}
# item_types = ["CSV"]

# csv_item = gis.content.add(item_properties=item_prop, data=cwd+'\\'+"pov_ga_us.csv")
# table_item=csv_item.publish()
# csv_item.move("pov_fromScript")
# csv_item.share(groups="e282b0573aa14a63bd4f131b1fbaab8e")
# print("updated csv")
# #inital publishing end

#getting the id of the table that we'll overwrite
table_item.share(groups="e282b0573aa14a63bd4f131b1fbaab8e")
table_id=table_item.share(groups="e282b0573aa14a63bd4f131b1fbaab8e")['results'][0]['itemId']

from arcgis.features import FeatureLayerCollection

#Updating the hosted table that contains GA & US info
commRecTable = gis.content.get(table_id)
commRec_collection = FeatureLayerCollection.fromitem(commRecTable)
commRec_collection.manager.overwrite(cwd+'\\'+"pov_ga_us.csv")
